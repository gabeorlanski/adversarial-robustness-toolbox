{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MMAction2 Model",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "81b72f3730d94605bca0a4cac770cb31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5da01a84f14348d3bd82e0b5bd70d1eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a9749011df434b54b2356ad3b9052b65",
              "IPY_MODEL_998610ae95d0413e884216158bb8ce36"
            ]
          }
        },
        "5da01a84f14348d3bd82e0b5bd70d1eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9749011df434b54b2356ad3b9052b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_00040b7a133a4479a3d199fd10d3245f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3253cb66cd4b4be0a111a92dffd5a062"
          }
        },
        "998610ae95d0413e884216158bb8ce36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f52789e2a8d04712b2e4dad72b37a1bd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 119MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8356bb50a88147d9958eb9934e56e83a"
          }
        },
        "00040b7a133a4479a3d199fd10d3245f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3253cb66cd4b4be0a111a92dffd5a062": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f52789e2a8d04712b2e4dad72b37a1bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8356bb50a88147d9958eb9934e56e83a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5abf1bbf3bd4dde9b78d8a43372ce88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7df478822ddd45a29dbc71e9f39a1882",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2907d6b54b1e463b899a0aaaf67b4b5d",
              "IPY_MODEL_6be46db68c84459f9e3b5165878c5f1c"
            ]
          }
        },
        "7df478822ddd45a29dbc71e9f39a1882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2907d6b54b1e463b899a0aaaf67b4b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_34461d3de2ad4019acd8776c96b73e33",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 200,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 200,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ba89824e8654f32865028fbc049c443"
          }
        },
        "6be46db68c84459f9e3b5165878c5f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e72845e709f841ca90b71cf13eea30f8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 200/200 [02:33&lt;00:00,  1.30it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f2d3bdc715a4a7a8e4700fca5d4d3d6"
          }
        },
        "34461d3de2ad4019acd8776c96b73e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ba89824e8654f32865028fbc049c443": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e72845e709f841ca90b71cf13eea30f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f2d3bdc715a4a7a8e4700fca5d4d3d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcjSRFELVbNk"
      },
      "source": [
        "This originally was the MMAction2 Tutorial. I gutted it for our purposes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf8PpPXtVvmg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44e75184-14be-4ce3-cb7d-38cf9a6e5451"
      },
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "PD_Twhir8n1H"
      },
      "source": [
        "# Load python modules needed\n",
        "\n",
        "Similar to how you do pip install a dependency when using your computer, you must install the python packages in colab. We will need to add the install of our fork to this as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PAJ4ArzV5Ry",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e0579ab7-ef0a-4045-9d82-8284c8f82af1"
      },
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "!pip install -U torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install mmcv-full thus we could use CUDA operators\n",
        "!pip install mmcv-full==latest+torch1.5.0+cu101 -f https://download.openmmlab.com/mmcv/dist/index.html\n",
        "\n",
        "# Install mmaction2\n",
        "!rm -rf mmaction2\n",
        "!git clone https://github.com/open-mmlab/mmaction2.git\n",
        "%cd mmaction2\n",
        "\n",
        "!pip install -e .\n",
        "\n",
        "# Install some optional requirements\n",
        "!pip install -r requirements/optional.txt\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 65.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1+cu101) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.6.1+cu101) (7.1.2)\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.5.1+cu101 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/index.html\n",
            "Collecting mmcv-full==latest+torch1.5.0+cu101\n",
            "\u001b[?25l  Downloading https://download.openmmlab.com/mmcv/dist/1.3.1/torch1.5.0/cu101/mmcv_full-latest%2Btorch1.5.0%2Bcu101-cp37-cp37m-manylinux1_x86_64.whl (24.4MB)\n",
            "\u001b[K     |████████████████████████████████| 24.4MB 221kB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full==latest+torch1.5.0+cu101) (7.1.2)\n",
            "Collecting addict\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/00/b08f23b7d7e1e14ce01419a467b583edbb93c6cdb8654e54a9cc579cd61f/addict-2.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full==latest+torch1.5.0+cu101) (3.13)\n",
            "Collecting yapf\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/0d/8814e79eb865eab42d95023b58b650d01dec6f8ea87fc9260978b1bf2167/yapf-0.31.0-py2.py3-none-any.whl (185kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full==latest+torch1.5.0+cu101) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full==latest+torch1.5.0+cu101) (4.1.2.30)\n",
            "Installing collected packages: addict, yapf, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.3.1 yapf-0.31.0\n",
            "Cloning into 'mmaction2'...\n",
            "remote: Enumerating objects: 10335, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 10335 (delta 25), reused 19 (delta 3), pack-reused 10262\u001b[K\n",
            "Receiving objects: 100% (10335/10335), 36.54 MiB | 25.38 MiB/s, done.\n",
            "Resolving deltas: 100% (7329/7329), done.\n",
            "/content/mmaction2\n",
            "Obtaining file:///content/mmaction2\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmaction2==0.13.0) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmaction2==0.13.0) (1.19.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mmaction2==0.13.0) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmaction2==0.13.0) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmaction2==0.13.0) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmaction2==0.13.0) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmaction2==0.13.0) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmaction2==0.13.0) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mmaction2==0.13.0) (1.15.0)\n",
            "Installing collected packages: mmaction2\n",
            "  Running setup.py develop for mmaction2\n",
            "Successfully installed mmaction2\n",
            "Collecting av\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/ff/bacde7314c646a2bd2f240034809a10cc3f8b096751284d0828640fff3dd/av-8.0.3-cp37-cp37m-manylinux2010_x86_64.whl (37.2MB)\n",
            "\u001b[K     |████████████████████████████████| 37.2MB 135kB/s \n",
            "\u001b[?25hCollecting decord>=0.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/5e/e2be6a3a3a46275059574d9c6a1d422aa6c7c3cbf6614939b8a3c3f8f2d5/decord-0.5.2-py3-none-manylinux2010_x86_64.whl (14.1MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1MB 48.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (from -r requirements/optional.txt (line 3)) (0.2.9)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (from -r requirements/optional.txt (line 4)) (0.8.0)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from -r requirements/optional.txt (line 5)) (0.99)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (from -r requirements/optional.txt (line 6)) (0.2.3.5)\n",
            "Collecting onnx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/57/65f48111f823df02da3e391b0b1aaadaf9972f8aa68ab3a41f46d59f57fe/onnx-1.8.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5MB 44.9MB/s \n",
            "\u001b[?25hCollecting onnxruntime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/f0/666d6e3ceaa276a54e728f9972732e058544cbb6a3e1a778a8d6f87132c1/onnxruntime-1.7.0-cp37-cp37m-manylinux2014_x86_64.whl (4.1MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1MB 41.9MB/s \n",
            "\u001b[?25hCollecting PyTurboJPEG\n",
            "  Downloading https://files.pythonhosted.org/packages/16/26/a8664026d4023cfd02937ef30420234f81c51962c9269d79265f5c889f9c/PyTurboJPEG-1.4.2.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from decord>=0.4.1->-r requirements/optional.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (2.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (0.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (1.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (4.1.2.30)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug->-r requirements/optional.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (0.22.2.post1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (0.2.2)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (0.10.3.post1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (2.1.9)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (0.51.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa->-r requirements/optional.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->-r requirements/optional.txt (line 6)) (4.41.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx->-r requirements/optional.txt (line 7)) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx->-r requirements/optional.txt (line 7)) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (2.4.7)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug->-r requirements/optional.txt (line 3)) (2.5.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug->-r requirements/optional.txt (line 3)) (1.1.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.9.0->librosa->-r requirements/optional.txt (line 4)) (1.14.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->-r requirements/optional.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->-r requirements/optional.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->-r requirements/optional.txt (line 4)) (20.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa->-r requirements/optional.txt (line 4)) (54.2.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa->-r requirements/optional.txt (line 4)) (0.34.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa->-r requirements/optional.txt (line 4)) (2.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa->-r requirements/optional.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa->-r requirements/optional.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa->-r requirements/optional.txt (line 4)) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa->-r requirements/optional.txt (line 4)) (2.10)\n",
            "Building wheels for collected packages: PyTurboJPEG\n",
            "  Building wheel for PyTurboJPEG (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyTurboJPEG: filename=PyTurboJPEG-1.4.2-cp37-none-any.whl size=7051 sha256=b99ec97f61856a9fdda7c9fd24d0c505b7a3ad4b4e85f08db9d19793739e6ae3\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/be/50/f7ac9256e214e497071d920700b604e554a4034eedbc8afe32\n",
            "Successfully built PyTurboJPEG\n",
            "Installing collected packages: av, decord, onnx, onnxruntime, PyTurboJPEG\n",
            "Successfully installed PyTurboJPEG-1.4.2 av-8.0.3 decord-0.5.2 onnx-1.8.1 onnxruntime-1.7.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "configs  docs\t     mmaction\t\t README_zh-CN.md   setup.cfg  tools\n",
            "demo\t docs_zh_CN  mmaction2.egg-info  requirements\t   setup.py\n",
            "docker\t LICENSE     README.md\t\t requirements.txt  tests\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No_zZAFpWC-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b26db1c1-acef-41a0-dffa-2743d9dfcb51"
      },
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMAction2 installation\n",
        "import mmaction\n",
        "print(mmaction.__version__)\n",
        "\n",
        "# Check MMCV installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.1+cu101 True\n",
            "0.13.0\n",
            "10.1\n",
            "GCC 7.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXf7oV5DWdab"
      },
      "source": [
        "# Loading The Model From the Checkpoint\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64CW6d_AaT-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62183359-b2e4-4266-d566-73bcdea949b8"
      },
      "source": [
        "!mkdir checkpoints\n",
        "!wget -c https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_1x1x3_100e_kinetics400_rgb/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth \\\n",
        "      -O checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-16 20:47:18--  https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_1x1x3_100e_kinetics400_rgb/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 47.75.20.25\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|47.75.20.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 97579339 (93M) [application/octet-stream]\n",
            "Saving to: ‘checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth’\n",
            "\n",
            "checkpoints/tsn_r50 100%[===================>]  93.06M  8.54MB/s    in 13s     \n",
            "\n",
            "2021-04-16 20:47:31 (7.32 MB/s) - ‘checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth’ saved [97579339/97579339]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNZB7NoSabzj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8adbe6db-c2b8-48cc-c684-07018265c592"
      },
      "source": [
        "from mmaction.apis import inference_recognizer, init_recognizer\n",
        "\n",
        "# Choose to use a config and initialize the recognizer\n",
        "config = 'configs/recognition/tsn/tsn_r50_video_inference_1x1x3_100e_kinetics400_rgb.py'\n",
        "# Setup a checkpoint file to load\n",
        "checkpoint = 'checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
        "# Initialize the recognizer\n",
        "model = init_recognizer(config, checkpoint, device='cuda:0')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use load_from_local loader\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEMsBnpHapAn"
      },
      "source": [
        "# Use the recognizer to do inference\n",
        "video = 'demo/demo.mp4'\n",
        "label = 'demo/label_map_k400.txt'\n",
        "results = inference_recognizer(model, video, label)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIyJXqfWathq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05b85bda-29b9-4a53-c45e-405af843950c"
      },
      "source": [
        "# Let's show the results\n",
        "for result in results:\n",
        "    print(f'{result[0]}: ', result[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arm wrestling:  29.616438\n",
            "rock scissors paper:  10.75484\n",
            "shaking hands:  9.9084\n",
            "clapping:  9.189913\n",
            "massaging feet:  8.3053055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOP9-bO2f8t5"
      },
      "source": [
        "# Loading the Data\n",
        "\n",
        "This is where the data is loaded, we will need to overwrite this part and add in our data. This can either be the functions to sample and download the files OR it can be a link to a dropbox, Google drive, or other type of file hosting thing.\n",
        "\n",
        "We will also need to make sure our code outputs the same file structure that they do in the subsection \"Their Labels Format\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjsUj9JzgUlJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1fdb9e8-4f3b-4889-efd7-c1cce0b4046e"
      },
      "source": [
        "# download, decompress the data\n",
        "!rm kinetics400_tiny.zip*\n",
        "!rm -rf kinetics400_tiny\n",
        "!wget https://download.openmmlab.com/mmaction/kinetics400_tiny.zip\n",
        "!unzip kinetics400_tiny.zip > /dev/null"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'kinetics400_tiny.zip*': No such file or directory\n",
            "--2021-04-16 20:47:40--  https://download.openmmlab.com/mmaction/kinetics400_tiny.zip\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 47.75.20.25\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|47.75.20.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18308682 (17M) [application/zip]\n",
            "Saving to: ‘kinetics400_tiny.zip’\n",
            "\n",
            "kinetics400_tiny.zi 100%[===================>]  17.46M  10.3MB/s    in 1.7s    \n",
            "\n",
            "2021-04-16 20:47:42 (10.3 MB/s) - ‘kinetics400_tiny.zip’ saved [18308682/18308682]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbZ-o7V6hNw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "538c07f2-1d81-43c7-860f-1134eead4320"
      },
      "source": [
        "# Check the directory structure of the tiny data\n",
        "\n",
        "# Install tree first\n",
        "!apt-get -q install tree\n",
        "!tree kinetics400_tiny"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 31 not upgraded.\n",
            "Need to get 40.7 kB of archives.\n",
            "After this operation, 105 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tree amd64 1.7.0-5 [40.7 kB]\n",
            "Fetched 40.7 kB in 1s (46.4 kB/s)\n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 160983 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_1.7.0-5_amd64.deb ...\n",
            "Unpacking tree (1.7.0-5) ...\n",
            "Setting up tree (1.7.0-5) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "kinetics400_tiny\n",
            "├── kinetics_tiny_train_video.txt\n",
            "├── kinetics_tiny_val_video.txt\n",
            "├── train\n",
            "│   ├── 27_CSXByd3s.mp4\n",
            "│   ├── 34XczvTaRiI.mp4\n",
            "│   ├── A-wiliK50Zw.mp4\n",
            "│   ├── D32_1gwq35E.mp4\n",
            "│   ├── D92m0HsHjcQ.mp4\n",
            "│   ├── DbX8mPslRXg.mp4\n",
            "│   ├── FMlSTTpN3VY.mp4\n",
            "│   ├── h10B9SVE-nk.mp4\n",
            "│   ├── h2YqqUhnR34.mp4\n",
            "│   ├── iRuyZSKhHRg.mp4\n",
            "│   ├── IyfILH9lBRo.mp4\n",
            "│   ├── kFC3KY2bOP8.mp4\n",
            "│   ├── LvcFDgCAXQs.mp4\n",
            "│   ├── O46YA8tI530.mp4\n",
            "│   ├── oMrZaozOvdQ.mp4\n",
            "│   ├── oXy-e_P_cAI.mp4\n",
            "│   ├── P5M-hAts7MQ.mp4\n",
            "│   ├── phDqGd0NKoo.mp4\n",
            "│   ├── PnOe3GZRVX8.mp4\n",
            "│   ├── R8HXQkdgKWA.mp4\n",
            "│   ├── RqnKtCEoEcA.mp4\n",
            "│   ├── soEcZZsBmDs.mp4\n",
            "│   ├── TkkZPZHbAKA.mp4\n",
            "│   ├── T_TMNGzVrDk.mp4\n",
            "│   ├── WaS0qwP46Us.mp4\n",
            "│   ├── Wh_YPQdH1Zg.mp4\n",
            "│   ├── WWP5HZJsg-o.mp4\n",
            "│   ├── xGY2dP0YUjA.mp4\n",
            "│   ├── yLC9CtWU5ws.mp4\n",
            "│   └── ZQV4U2KQ370.mp4\n",
            "└── val\n",
            "    ├── 0pVGiAU6XEA.mp4\n",
            "    ├── AQrbRSnRt8M.mp4\n",
            "    ├── b6Q_b7vgc7Q.mp4\n",
            "    ├── ddvJ6-faICE.mp4\n",
            "    ├── IcLztCtvhb8.mp4\n",
            "    ├── ik4BW3-SCts.mp4\n",
            "    ├── jqRrH30V0k4.mp4\n",
            "    ├── SU_x2LQqSLs.mp4\n",
            "    ├── u4Rm6srmIS8.mp4\n",
            "    └── y5Iu7XkTqV0.mp4\n",
            "\n",
            "2 directories, 42 files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRyJbHybRflo"
      },
      "source": [
        "## Their Labels Format\n",
        "\n",
        "We can either format our data like this, OR we can adjust the config to handle whatever format we want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTdi6dI0hY3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b965b31-00bb-4645-f860-ae8590c3be43"
      },
      "source": [
        "# After downloading the data, we need to check the annotation format\n",
        "!cat kinetics400_tiny/kinetics_tiny_train_video.txt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D32_1gwq35E.mp4 0\n",
            "iRuyZSKhHRg.mp4 1\n",
            "oXy-e_P_cAI.mp4 0\n",
            "34XczvTaRiI.mp4 1\n",
            "h2YqqUhnR34.mp4 0\n",
            "O46YA8tI530.mp4 0\n",
            "kFC3KY2bOP8.mp4 1\n",
            "WWP5HZJsg-o.mp4 1\n",
            "phDqGd0NKoo.mp4 1\n",
            "yLC9CtWU5ws.mp4 0\n",
            "27_CSXByd3s.mp4 1\n",
            "IyfILH9lBRo.mp4 1\n",
            "T_TMNGzVrDk.mp4 1\n",
            "TkkZPZHbAKA.mp4 0\n",
            "PnOe3GZRVX8.mp4 1\n",
            "soEcZZsBmDs.mp4 1\n",
            "FMlSTTpN3VY.mp4 1\n",
            "WaS0qwP46Us.mp4 0\n",
            "A-wiliK50Zw.mp4 1\n",
            "oMrZaozOvdQ.mp4 1\n",
            "ZQV4U2KQ370.mp4 0\n",
            "DbX8mPslRXg.mp4 1\n",
            "h10B9SVE-nk.mp4 1\n",
            "P5M-hAts7MQ.mp4 0\n",
            "R8HXQkdgKWA.mp4 0\n",
            "D92m0HsHjcQ.mp4 0\n",
            "RqnKtCEoEcA.mp4 0\n",
            "LvcFDgCAXQs.mp4 0\n",
            "xGY2dP0YUjA.mp4 0\n",
            "Wh_YPQdH1Zg.mp4 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bq0mxmEi29H"
      },
      "source": [
        "According to the format defined in [`VideoDataset`](./datasets/video_dataset.py), each line indicates a sample video with the filepath and label, which are split with a whitespace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht_DGJA9jQar"
      },
      "source": [
        "# Load/Modify the config of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjCcmCKOjktc"
      },
      "source": [
        "from mmcv import Config\n",
        "cfg = Config.fromfile('./configs/recognition/tsn/tsn_r50_video_1x1x8_100e_kinetics400_rgb.py')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc8YhFFGjp3e"
      },
      "source": [
        "Modify the config loaded in previous cell for the task. The only things we need to change are the paths to the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlhu9byjjt-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3559c3ca-aa8f-4b86-ec83-237d909e2f52"
      },
      "source": [
        "from mmcv.runner import set_random_seed\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = 'VideoDataset'\n",
        "cfg.data_root = 'kinetics400_tiny/train/'\n",
        "cfg.data_root_val = 'kinetics400_tiny/val/'\n",
        "cfg.ann_file_train = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
        "cfg.ann_file_val = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
        "cfg.ann_file_test = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
        "\n",
        "cfg.data.test.type = 'VideoDataset'\n",
        "cfg.data.test.ann_file = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
        "cfg.data.test.data_prefix = 'kinetics400_tiny/val/'\n",
        "\n",
        "cfg.data.train.type = 'VideoDataset'\n",
        "cfg.data.train.ann_file = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
        "cfg.data.train.data_prefix = 'kinetics400_tiny/train/'\n",
        "\n",
        "cfg.data.val.type = 'VideoDataset'\n",
        "cfg.data.val.ann_file = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
        "cfg.data.val.data_prefix = 'kinetics400_tiny/val/'\n",
        "\n",
        "# The flag is used to determine whether it is omnisource training\n",
        "cfg.setdefault('omnisource', False)\n",
        "# Modify num classes of the model in cls_head\n",
        "cfg.model.cls_head.num_classes = 2\n",
        "# We can use the pre-trained TSN model\n",
        "cfg.load_from = './checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './tutorial_exps'\n",
        "\n",
        "# The original learning rate (LR) is set for 8-GPU training.\n",
        "# We divide it by 8 since we only use one GPU.\n",
        "cfg.data.videos_per_gpu = cfg.data.videos_per_gpu // 16\n",
        "cfg.optimizer.lr = cfg.optimizer.lr / 8 / 16\n",
        "cfg.total_epochs = 30\n",
        "\n",
        "# We can set the checkpoint saving interval to reduce the storage cost\n",
        "cfg.checkpoint_config.interval = 10\n",
        "# We can set the log print interval to reduce the the times of printing log\n",
        "cfg.log_config.interval = 5\n",
        "\n",
        "# Set seed thus the results are more reproducible\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "\n",
        "\n",
        "# We can initialize the logger for training and have a look\n",
        "# at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Config:\n",
            "model = dict(\n",
            "    type='Recognizer2D',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        pretrained='torchvision://resnet50',\n",
            "        depth=50,\n",
            "        norm_eval=False),\n",
            "    cls_head=dict(\n",
            "        type='TSNHead',\n",
            "        num_classes=2,\n",
            "        in_channels=2048,\n",
            "        spatial_type='avg',\n",
            "        consensus=dict(type='AvgConsensus', dim=1),\n",
            "        dropout_ratio=0.4,\n",
            "        init_std=0.01),\n",
            "    train_cfg=None,\n",
            "    test_cfg=dict(average_clips=None))\n",
            "optimizer = dict(type='SGD', lr=7.8125e-05, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
            "lr_config = dict(policy='step', step=[40, 80])\n",
            "total_epochs = 30\n",
            "checkpoint_config = dict(interval=10)\n",
            "log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = './checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "dataset_type = 'VideoDataset'\n",
            "data_root = 'kinetics400_tiny/train/'\n",
            "data_root_val = 'kinetics400_tiny/val/'\n",
            "ann_file_train = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
            "ann_file_val = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
            "ann_file_test = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
            "train_pipeline = [\n",
            "    dict(type='DecordInit'),\n",
            "    dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=8),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(\n",
            "        type='MultiScaleCrop',\n",
            "        input_size=224,\n",
            "        scales=(1, 0.875, 0.75, 0.66),\n",
            "        random_crop=False,\n",
            "        max_wh_scale_gap=1),\n",
            "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
            "    dict(type='Flip', flip_ratio=0.5),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_bgr=False),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
            "]\n",
            "val_pipeline = [\n",
            "    dict(type='DecordInit'),\n",
            "    dict(\n",
            "        type='SampleFrames',\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=8,\n",
            "        test_mode=True),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(-1, 256)),\n",
            "    dict(type='CenterCrop', crop_size=224),\n",
            "    dict(type='Flip', flip_ratio=0),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_bgr=False),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "    dict(type='ToTensor', keys=['imgs'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='DecordInit'),\n",
            "    dict(\n",
            "        type='SampleFrames',\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=25,\n",
            "        test_mode=True),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(-1, 256)),\n",
            "    dict(type='ThreeCrop', crop_size=256),\n",
            "    dict(type='Flip', flip_ratio=0),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_bgr=False),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "    dict(type='ToTensor', keys=['imgs'])\n",
            "]\n",
            "data = dict(\n",
            "    videos_per_gpu=2,\n",
            "    workers_per_gpu=4,\n",
            "    train=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_train_video.txt',\n",
            "        data_prefix='kinetics400_tiny/train/',\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit'),\n",
            "            dict(\n",
            "                type='SampleFrames', clip_len=1, frame_interval=1,\n",
            "                num_clips=8),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(\n",
            "                type='MultiScaleCrop',\n",
            "                input_size=224,\n",
            "                scales=(1, 0.875, 0.75, 0.66),\n",
            "                random_crop=False,\n",
            "                max_wh_scale_gap=1),\n",
            "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
            "            dict(type='Flip', flip_ratio=0.5),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_bgr=False),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
            "        data_prefix='kinetics400_tiny/val/',\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit'),\n",
            "            dict(\n",
            "                type='SampleFrames',\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=8,\n",
            "                test_mode=True),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(-1, 256)),\n",
            "            dict(type='CenterCrop', crop_size=224),\n",
            "            dict(type='Flip', flip_ratio=0),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_bgr=False),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "            dict(type='ToTensor', keys=['imgs'])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
            "        data_prefix='kinetics400_tiny/val/',\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit'),\n",
            "            dict(\n",
            "                type='SampleFrames',\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=25,\n",
            "                test_mode=True),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(-1, 256)),\n",
            "            dict(type='ThreeCrop', crop_size=256),\n",
            "            dict(type='Flip', flip_ratio=0),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_bgr=False),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "            dict(type='ToTensor', keys=['imgs'])\n",
            "        ]))\n",
            "evaluation = dict(\n",
            "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
            "work_dir = './tutorial_exps'\n",
            "omnisource = False\n",
            "seed = 0\n",
            "gpu_ids = range(0, 1)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tES-qnZ3k38Z"
      },
      "source": [
        "# Training\n",
        "\n",
        "Training loop of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDBWkdDRk6oz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "81b72f3730d94605bca0a4cac770cb31",
            "5da01a84f14348d3bd82e0b5bd70d1eb",
            "a9749011df434b54b2356ad3b9052b65",
            "998610ae95d0413e884216158bb8ce36",
            "00040b7a133a4479a3d199fd10d3245f",
            "3253cb66cd4b4be0a111a92dffd5a062",
            "f52789e2a8d04712b2e4dad72b37a1bd",
            "8356bb50a88147d9958eb9934e56e83a"
          ]
        },
        "outputId": "71e33b24-7226-4d19-87e4-0045437f8a0f"
      },
      "source": [
        "import os.path as osp\n",
        "\n",
        "from mmaction.datasets import build_dataset\n",
        "from mmaction.models import build_model\n",
        "from mmaction.apis import train_model\n",
        "\n",
        "import mmcv\n",
        "\n",
        "# Build the dataset\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "\n",
        "# Build the recognizer\n",
        "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
        "\n",
        "# Create work_dir\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "train_model(model, datasets, cfg, distributed=False, validate=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use load_from_torchvision loader\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81b72f3730d94605bca0a4cac770cb31",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 20:47:51,113 - mmaction - INFO - These parameters in pretrained checkpoint are not loaded: {'fc.bias', 'fc.weight'}\n",
            "2021-04-16 20:47:51,167 - mmaction - INFO - load checkpoint from ./checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n",
            "2021-04-16 20:47:51,168 - mmaction - INFO - Use load_from_local loader\n",
            "2021-04-16 20:47:51,266 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 2048]) from checkpoint, the shape in current model is torch.Size([2, 2048]).\n",
            "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "2021-04-16 20:47:51,270 - mmaction - INFO - Start running, host: root@1e09db466fec, work_dir: /content/mmaction2/tutorial_exps\n",
            "2021-04-16 20:47:51,271 - mmaction - INFO - workflow: [('train', 1)], max: 30 epochs\n",
            "/content/mmaction2/mmaction/core/evaluation/eval_hooks.py:131: UserWarning: runner.meta is None. Creating a empty one.\n",
            "  warnings.warn('runner.meta is None. Creating a empty one.')\n",
            "2021-04-16 20:47:55,755 - mmaction - INFO - Epoch [1][5/15]\tlr: 7.813e-05, eta: 0:06:38, time: 0.896, data_time: 0.751, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6865, loss: 0.6865, grad_norm: 12.7663\n",
            "2021-04-16 20:47:56,598 - mmaction - INFO - Epoch [1][10/15]\tlr: 7.813e-05, eta: 0:03:54, time: 0.169, data_time: 0.041, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.7171, loss: 0.7171, grad_norm: 13.7445\n",
            "2021-04-16 20:47:57,364 - mmaction - INFO - Epoch [1][15/15]\tlr: 7.813e-05, eta: 0:02:56, time: 0.153, data_time: 0.072, memory: 2918, top1_acc: 0.2000, top5_acc: 1.0000, loss_cls: 0.8884, loss: 0.8884, grad_norm: 14.7140\n",
            "2021-04-16 20:48:01,574 - mmaction - INFO - Epoch [2][5/15]\tlr: 7.813e-05, eta: 0:03:39, time: 0.825, data_time: 0.676, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.6562, loss: 0.6562, grad_norm: 10.5716\n",
            "2021-04-16 20:48:02,774 - mmaction - INFO - Epoch [2][10/15]\tlr: 7.813e-05, eta: 0:03:13, time: 0.240, data_time: 0.086, memory: 2918, top1_acc: 0.2000, top5_acc: 1.0000, loss_cls: 0.7480, loss: 0.7480, grad_norm: 11.7083\n",
            "2021-04-16 20:48:03,599 - mmaction - INFO - Epoch [2][15/15]\tlr: 7.813e-05, eta: 0:02:51, time: 0.165, data_time: 0.089, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6735, loss: 0.6735, grad_norm: 12.8067\n",
            "2021-04-16 20:48:07,512 - mmaction - INFO - Epoch [3][5/15]\tlr: 7.813e-05, eta: 0:03:10, time: 0.766, data_time: 0.648, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.7218, loss: 0.7218, grad_norm: 12.4894\n",
            "2021-04-16 20:48:08,890 - mmaction - INFO - Epoch [3][10/15]\tlr: 7.813e-05, eta: 0:02:58, time: 0.274, data_time: 0.152, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.6188, loss: 0.6188, grad_norm: 11.8113\n",
            "2021-04-16 20:48:09,616 - mmaction - INFO - Epoch [3][15/15]\tlr: 7.813e-05, eta: 0:02:43, time: 0.147, data_time: 0.057, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.7298, loss: 0.7298, grad_norm: 12.5042\n",
            "2021-04-16 20:48:13,922 - mmaction - INFO - Epoch [4][5/15]\tlr: 7.813e-05, eta: 0:02:59, time: 0.844, data_time: 0.715, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.6833, loss: 0.6833, grad_norm: 10.1039\n",
            "2021-04-16 20:48:15,053 - mmaction - INFO - Epoch [4][10/15]\tlr: 7.813e-05, eta: 0:02:48, time: 0.226, data_time: 0.103, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6640, loss: 0.6640, grad_norm: 11.7608\n",
            "2021-04-16 20:48:15,667 - mmaction - INFO - Epoch [4][15/15]\tlr: 7.813e-05, eta: 0:02:36, time: 0.123, data_time: 0.034, memory: 2918, top1_acc: 0.3000, top5_acc: 1.0000, loss_cls: 0.7373, loss: 0.7373, grad_norm: 13.6150\n",
            "2021-04-16 20:48:19,829 - mmaction - INFO - Epoch [5][5/15]\tlr: 7.813e-05, eta: 0:02:46, time: 0.802, data_time: 0.665, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.6309, loss: 0.6309, grad_norm: 11.1852\n",
            "2021-04-16 20:48:20,867 - mmaction - INFO - Epoch [5][10/15]\tlr: 7.813e-05, eta: 0:02:38, time: 0.207, data_time: 0.064, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.7178, loss: 0.7178, grad_norm: 12.3945\n",
            "2021-04-16 20:48:21,912 - mmaction - INFO - Epoch [5][15/15]\tlr: 7.813e-05, eta: 0:02:31, time: 0.209, data_time: 0.132, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.7093, loss: 0.7093, grad_norm: 12.4626\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 5.3 task/s, elapsed: 2s, ETA:     0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 20:48:23,969 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
            "2021-04-16 20:48:23,971 - mmaction - INFO - \n",
            "top1_acc\t0.7000\n",
            "top5_acc\t1.0000\n",
            "2021-04-16 20:48:23,972 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
            "2021-04-16 20:48:23,982 - mmaction - INFO - \n",
            "mean_acc\t0.7000\n",
            "2021-04-16 20:48:24,328 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_5.pth.\n",
            "2021-04-16 20:48:24,329 - mmaction - INFO - Best top1_acc is 0.7000 at 5 epoch.\n",
            "2021-04-16 20:48:24,335 - mmaction - INFO - Epoch(val) [5][15]\ttop1_acc: 0.7000, top5_acc: 1.0000, mean_class_accuracy: 0.7000\n",
            "2021-04-16 20:48:29,209 - mmaction - INFO - Epoch [6][5/15]\tlr: 7.813e-05, eta: 0:02:42, time: 0.974, data_time: 0.835, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.6695, loss: 0.6695, grad_norm: 11.0237\n",
            "2021-04-16 20:48:29,963 - mmaction - INFO - Epoch [6][10/15]\tlr: 7.813e-05, eta: 0:02:33, time: 0.151, data_time: 0.032, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6824, loss: 0.6824, grad_norm: 11.8899\n",
            "2021-04-16 20:48:30,475 - mmaction - INFO - Epoch [6][15/15]\tlr: 7.813e-05, eta: 0:02:25, time: 0.102, data_time: 0.030, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6870, loss: 0.6870, grad_norm: 13.7294\n",
            "2021-04-16 20:48:34,795 - mmaction - INFO - Epoch [7][5/15]\tlr: 7.813e-05, eta: 0:02:31, time: 0.845, data_time: 0.692, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6458, loss: 0.6458, grad_norm: 10.8094\n",
            "2021-04-16 20:48:35,815 - mmaction - INFO - Epoch [7][10/15]\tlr: 7.813e-05, eta: 0:02:25, time: 0.204, data_time: 0.070, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.6005, loss: 0.6005, grad_norm: 9.5426\n",
            "2021-04-16 20:48:36,630 - mmaction - INFO - Epoch [7][15/15]\tlr: 7.813e-05, eta: 0:02:19, time: 0.163, data_time: 0.083, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6828, loss: 0.6828, grad_norm: 12.0918\n",
            "2021-04-16 20:48:40,912 - mmaction - INFO - Epoch [8][5/15]\tlr: 7.813e-05, eta: 0:02:24, time: 0.837, data_time: 0.714, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.6921, loss: 0.6921, grad_norm: 13.1961\n",
            "2021-04-16 20:48:42,239 - mmaction - INFO - Epoch [8][10/15]\tlr: 7.813e-05, eta: 0:02:19, time: 0.264, data_time: 0.156, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6074, loss: 0.6074, grad_norm: 11.3635\n",
            "2021-04-16 20:48:42,724 - mmaction - INFO - Epoch [8][15/15]\tlr: 7.813e-05, eta: 0:02:13, time: 0.098, data_time: 0.018, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.7028, loss: 0.7028, grad_norm: 12.4428\n",
            "2021-04-16 20:48:46,701 - mmaction - INFO - Epoch [9][5/15]\tlr: 7.813e-05, eta: 0:02:15, time: 0.775, data_time: 0.672, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.5369, loss: 0.5369, grad_norm: 8.3901\n",
            "2021-04-16 20:48:48,493 - mmaction - INFO - Epoch [9][10/15]\tlr: 7.813e-05, eta: 0:02:13, time: 0.360, data_time: 0.234, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6797, loss: 0.6797, grad_norm: 12.8036\n",
            "2021-04-16 20:48:48,962 - mmaction - INFO - Epoch [9][15/15]\tlr: 7.813e-05, eta: 0:02:07, time: 0.094, data_time: 0.025, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5711, loss: 0.5711, grad_norm: 9.9661\n",
            "2021-04-16 20:48:53,135 - mmaction - INFO - Epoch [10][5/15]\tlr: 7.813e-05, eta: 0:02:09, time: 0.817, data_time: 0.678, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5378, loss: 0.5378, grad_norm: 8.8747\n",
            "2021-04-16 20:48:54,514 - mmaction - INFO - Epoch [10][10/15]\tlr: 7.813e-05, eta: 0:02:06, time: 0.276, data_time: 0.144, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.6643, loss: 0.6643, grad_norm: 12.6166\n",
            "2021-04-16 20:48:55,265 - mmaction - INFO - Epoch [10][15/15]\tlr: 7.813e-05, eta: 0:02:01, time: 0.150, data_time: 0.064, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.7041, loss: 0.7041, grad_norm: 12.4961\n",
            "2021-04-16 20:48:55,354 - mmaction - INFO - Saving checkpoint at 10 epochs\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 5.3 task/s, elapsed: 2s, ETA:     0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 20:48:57,670 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
            "2021-04-16 20:48:57,672 - mmaction - INFO - \n",
            "top1_acc\t0.9000\n",
            "top5_acc\t1.0000\n",
            "2021-04-16 20:48:57,673 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
            "2021-04-16 20:48:57,680 - mmaction - INFO - \n",
            "mean_acc\t0.9000\n",
            "2021-04-16 20:48:58,034 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_10.pth.\n",
            "2021-04-16 20:48:58,035 - mmaction - INFO - Best top1_acc is 0.9000 at 10 epoch.\n",
            "2021-04-16 20:48:58,037 - mmaction - INFO - Epoch(val) [10][15]\ttop1_acc: 0.9000, top5_acc: 1.0000, mean_class_accuracy: 0.9000\n",
            "2021-04-16 20:49:02,026 - mmaction - INFO - Epoch [11][5/15]\tlr: 7.813e-05, eta: 0:02:03, time: 0.796, data_time: 0.669, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5357, loss: 0.5357, grad_norm: 8.8076\n",
            "2021-04-16 20:49:03,087 - mmaction - INFO - Epoch [11][10/15]\tlr: 7.813e-05, eta: 0:01:59, time: 0.212, data_time: 0.086, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5830, loss: 0.5830, grad_norm: 10.5869\n",
            "2021-04-16 20:49:04,105 - mmaction - INFO - Epoch [11][15/15]\tlr: 7.813e-05, eta: 0:01:55, time: 0.204, data_time: 0.117, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6231, loss: 0.6231, grad_norm: 11.3669\n",
            "2021-04-16 20:49:08,532 - mmaction - INFO - Epoch [12][5/15]\tlr: 7.813e-05, eta: 0:01:57, time: 0.866, data_time: 0.728, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5701, loss: 0.5701, grad_norm: 10.0686\n",
            "2021-04-16 20:49:09,506 - mmaction - INFO - Epoch [12][10/15]\tlr: 7.813e-05, eta: 0:01:53, time: 0.193, data_time: 0.074, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.5980, loss: 0.5980, grad_norm: 11.1718\n",
            "2021-04-16 20:49:10,119 - mmaction - INFO - Epoch [12][15/15]\tlr: 7.813e-05, eta: 0:01:49, time: 0.123, data_time: 0.033, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.6105, loss: 0.6105, grad_norm: 11.8516\n",
            "2021-04-16 20:49:14,158 - mmaction - INFO - Epoch [13][5/15]\tlr: 7.813e-05, eta: 0:01:49, time: 0.790, data_time: 0.641, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5438, loss: 0.5438, grad_norm: 10.4112\n",
            "2021-04-16 20:49:15,382 - mmaction - INFO - Epoch [13][10/15]\tlr: 7.813e-05, eta: 0:01:46, time: 0.245, data_time: 0.118, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6337, loss: 0.6337, grad_norm: 11.3883\n",
            "2021-04-16 20:49:16,091 - mmaction - INFO - Epoch [13][15/15]\tlr: 7.813e-05, eta: 0:01:42, time: 0.142, data_time: 0.055, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6328, loss: 0.6328, grad_norm: 12.0623\n",
            "2021-04-16 20:49:20,707 - mmaction - INFO - Epoch [14][5/15]\tlr: 7.813e-05, eta: 0:01:43, time: 0.907, data_time: 0.762, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6515, loss: 0.6515, grad_norm: 12.4932\n",
            "2021-04-16 20:49:21,747 - mmaction - INFO - Epoch [14][10/15]\tlr: 7.813e-05, eta: 0:01:40, time: 0.208, data_time: 0.111, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5537, loss: 0.5537, grad_norm: 10.5986\n",
            "2021-04-16 20:49:22,195 - mmaction - INFO - Epoch [14][15/15]\tlr: 7.813e-05, eta: 0:01:36, time: 0.090, data_time: 0.023, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.7072, loss: 0.7072, grad_norm: 12.8176\n",
            "2021-04-16 20:49:26,872 - mmaction - INFO - Epoch [15][5/15]\tlr: 7.813e-05, eta: 0:01:37, time: 0.918, data_time: 0.788, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6581, loss: 0.6581, grad_norm: 12.7124\n",
            "2021-04-16 20:49:27,812 - mmaction - INFO - Epoch [15][10/15]\tlr: 7.813e-05, eta: 0:01:34, time: 0.188, data_time: 0.068, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.4525, loss: 0.4525, grad_norm: 8.1148\n",
            "2021-04-16 20:49:28,310 - mmaction - INFO - Epoch [15][15/15]\tlr: 7.813e-05, eta: 0:01:30, time: 0.100, data_time: 0.017, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6320, loss: 0.6320, grad_norm: 11.7276\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 5.6 task/s, elapsed: 2s, ETA:     0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 20:49:30,262 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
            "2021-04-16 20:49:30,264 - mmaction - INFO - \n",
            "top1_acc\t0.8000\n",
            "top5_acc\t1.0000\n",
            "2021-04-16 20:49:30,265 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
            "2021-04-16 20:49:30,270 - mmaction - INFO - \n",
            "mean_acc\t0.8000\n",
            "2021-04-16 20:49:30,271 - mmaction - INFO - Epoch(val) [15][15]\ttop1_acc: 0.8000, top5_acc: 1.0000, mean_class_accuracy: 0.8000\n",
            "2021-04-16 20:49:34,509 - mmaction - INFO - Epoch [16][5/15]\tlr: 7.813e-05, eta: 0:01:30, time: 0.846, data_time: 0.715, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5428, loss: 0.5428, grad_norm: 10.0103\n",
            "2021-04-16 20:49:35,893 - mmaction - INFO - Epoch [16][10/15]\tlr: 7.813e-05, eta: 0:01:28, time: 0.277, data_time: 0.160, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6092, loss: 0.6092, grad_norm: 11.2150\n",
            "2021-04-16 20:49:36,339 - mmaction - INFO - Epoch [16][15/15]\tlr: 7.813e-05, eta: 0:01:24, time: 0.089, data_time: 0.022, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5308, loss: 0.5308, grad_norm: 9.9054\n",
            "2021-04-16 20:49:40,664 - mmaction - INFO - Epoch [17][5/15]\tlr: 7.813e-05, eta: 0:01:24, time: 0.848, data_time: 0.715, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6311, loss: 0.6311, grad_norm: 12.2289\n",
            "2021-04-16 20:49:41,967 - mmaction - INFO - Epoch [17][10/15]\tlr: 7.813e-05, eta: 0:01:21, time: 0.261, data_time: 0.145, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.6635, loss: 0.6635, grad_norm: 13.0179\n",
            "2021-04-16 20:49:42,430 - mmaction - INFO - Epoch [17][15/15]\tlr: 7.813e-05, eta: 0:01:18, time: 0.093, data_time: 0.018, memory: 2918, top1_acc: 1.0000, top5_acc: 1.0000, loss_cls: 0.4258, loss: 0.4258, grad_norm: 8.0280\n",
            "2021-04-16 20:49:46,552 - mmaction - INFO - Epoch [18][5/15]\tlr: 7.813e-05, eta: 0:01:18, time: 0.807, data_time: 0.689, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5798, loss: 0.5798, grad_norm: 11.0349\n",
            "2021-04-16 20:49:48,044 - mmaction - INFO - Epoch [18][10/15]\tlr: 7.813e-05, eta: 0:01:15, time: 0.299, data_time: 0.175, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.4536, loss: 0.4536, grad_norm: 8.3281\n",
            "2021-04-16 20:49:48,436 - mmaction - INFO - Epoch [18][15/15]\tlr: 7.813e-05, eta: 0:01:12, time: 0.078, data_time: 0.011, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4952, loss: 0.4952, grad_norm: 9.5805\n",
            "2021-04-16 20:49:53,007 - mmaction - INFO - Epoch [19][5/15]\tlr: 7.813e-05, eta: 0:01:12, time: 0.896, data_time: 0.743, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.5532, loss: 0.5532, grad_norm: 10.2697\n",
            "2021-04-16 20:49:54,009 - mmaction - INFO - Epoch [19][10/15]\tlr: 7.813e-05, eta: 0:01:09, time: 0.201, data_time: 0.079, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6116, loss: 0.6116, grad_norm: 11.5399\n",
            "2021-04-16 20:49:54,556 - mmaction - INFO - Epoch [19][15/15]\tlr: 7.813e-05, eta: 0:01:06, time: 0.109, data_time: 0.035, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4128, loss: 0.4128, grad_norm: 7.5754\n",
            "2021-04-16 20:49:58,994 - mmaction - INFO - Epoch [20][5/15]\tlr: 7.813e-05, eta: 0:01:05, time: 0.870, data_time: 0.731, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.4328, loss: 0.4328, grad_norm: 8.4830\n",
            "2021-04-16 20:50:00,067 - mmaction - INFO - Epoch [20][10/15]\tlr: 7.813e-05, eta: 0:01:03, time: 0.214, data_time: 0.105, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4623, loss: 0.4623, grad_norm: 8.9749\n",
            "2021-04-16 20:50:00,634 - mmaction - INFO - Epoch [20][15/15]\tlr: 7.813e-05, eta: 0:01:00, time: 0.114, data_time: 0.024, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5917, loss: 0.5917, grad_norm: 11.3900\n",
            "2021-04-16 20:50:00,723 - mmaction - INFO - Saving checkpoint at 20 epochs\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 5.5 task/s, elapsed: 2s, ETA:     0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 20:50:02,966 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
            "2021-04-16 20:50:02,968 - mmaction - INFO - \n",
            "top1_acc\t0.9000\n",
            "top5_acc\t1.0000\n",
            "2021-04-16 20:50:02,973 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
            "2021-04-16 20:50:02,976 - mmaction - INFO - \n",
            "mean_acc\t0.9000\n",
            "2021-04-16 20:50:02,978 - mmaction - INFO - Epoch(val) [20][15]\ttop1_acc: 0.9000, top5_acc: 1.0000, mean_class_accuracy: 0.9000\n",
            "2021-04-16 20:50:07,092 - mmaction - INFO - Epoch [21][5/15]\tlr: 7.813e-05, eta: 0:00:59, time: 0.822, data_time: 0.681, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4516, loss: 0.4516, grad_norm: 8.3886\n",
            "2021-04-16 20:50:08,390 - mmaction - INFO - Epoch [21][10/15]\tlr: 7.813e-05, eta: 0:00:56, time: 0.258, data_time: 0.134, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4543, loss: 0.4543, grad_norm: 9.0909\n",
            "2021-04-16 20:50:08,971 - mmaction - INFO - Epoch [21][15/15]\tlr: 7.813e-05, eta: 0:00:54, time: 0.117, data_time: 0.031, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5325, loss: 0.5325, grad_norm: 10.6040\n",
            "2021-04-16 20:50:13,100 - mmaction - INFO - Epoch [22][5/15]\tlr: 7.813e-05, eta: 0:00:53, time: 0.808, data_time: 0.673, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5642, loss: 0.5642, grad_norm: 10.7892\n",
            "2021-04-16 20:50:14,475 - mmaction - INFO - Epoch [22][10/15]\tlr: 7.813e-05, eta: 0:00:50, time: 0.275, data_time: 0.146, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5058, loss: 0.5058, grad_norm: 9.9743\n",
            "2021-04-16 20:50:15,077 - mmaction - INFO - Epoch [22][15/15]\tlr: 7.813e-05, eta: 0:00:48, time: 0.120, data_time: 0.036, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.4389, loss: 0.4389, grad_norm: 8.7588\n",
            "2021-04-16 20:50:19,401 - mmaction - INFO - Epoch [23][5/15]\tlr: 7.813e-05, eta: 0:00:47, time: 0.848, data_time: 0.704, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6278, loss: 0.6278, grad_norm: 12.5585\n",
            "2021-04-16 20:50:20,516 - mmaction - INFO - Epoch [23][10/15]\tlr: 7.813e-05, eta: 0:00:44, time: 0.223, data_time: 0.092, memory: 2918, top1_acc: 1.0000, top5_acc: 1.0000, loss_cls: 0.3285, loss: 0.3285, grad_norm: 6.4901\n",
            "2021-04-16 20:50:21,211 - mmaction - INFO - Epoch [23][15/15]\tlr: 7.813e-05, eta: 0:00:42, time: 0.139, data_time: 0.057, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4970, loss: 0.4970, grad_norm: 9.2489\n",
            "2021-04-16 20:50:25,520 - mmaction - INFO - Epoch [24][5/15]\tlr: 7.813e-05, eta: 0:00:40, time: 0.841, data_time: 0.690, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3844, loss: 0.3844, grad_norm: 7.6763\n",
            "2021-04-16 20:50:26,595 - mmaction - INFO - Epoch [24][10/15]\tlr: 7.813e-05, eta: 0:00:38, time: 0.215, data_time: 0.099, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.5461, loss: 0.5461, grad_norm: 11.7998\n",
            "2021-04-16 20:50:27,368 - mmaction - INFO - Epoch [24][15/15]\tlr: 7.813e-05, eta: 0:00:36, time: 0.155, data_time: 0.065, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3738, loss: 0.3738, grad_norm: 7.4752\n",
            "2021-04-16 20:50:31,463 - mmaction - INFO - Epoch [25][5/15]\tlr: 7.813e-05, eta: 0:00:34, time: 0.801, data_time: 0.652, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.5811, loss: 0.5811, grad_norm: 11.7458\n",
            "2021-04-16 20:50:32,609 - mmaction - INFO - Epoch [25][10/15]\tlr: 7.813e-05, eta: 0:00:32, time: 0.229, data_time: 0.100, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.5973, loss: 0.5973, grad_norm: 11.7810\n",
            "2021-04-16 20:50:33,401 - mmaction - INFO - Epoch [25][15/15]\tlr: 7.813e-05, eta: 0:00:30, time: 0.159, data_time: 0.070, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4511, loss: 0.4511, grad_norm: 9.2956\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 5.7 task/s, elapsed: 2s, ETA:     0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 20:50:35,321 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
            "2021-04-16 20:50:35,326 - mmaction - INFO - \n",
            "top1_acc\t1.0000\n",
            "top5_acc\t1.0000\n",
            "2021-04-16 20:50:35,328 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
            "2021-04-16 20:50:35,332 - mmaction - INFO - \n",
            "mean_acc\t1.0000\n",
            "2021-04-16 20:50:35,709 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_25.pth.\n",
            "2021-04-16 20:50:35,710 - mmaction - INFO - Best top1_acc is 1.0000 at 25 epoch.\n",
            "2021-04-16 20:50:35,717 - mmaction - INFO - Epoch(val) [25][15]\ttop1_acc: 1.0000, top5_acc: 1.0000, mean_class_accuracy: 1.0000\n",
            "2021-04-16 20:50:40,130 - mmaction - INFO - Epoch [26][5/15]\tlr: 7.813e-05, eta: 0:00:28, time: 0.881, data_time: 0.762, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3758, loss: 0.3758, grad_norm: 7.9655\n",
            "2021-04-16 20:50:41,149 - mmaction - INFO - Epoch [26][10/15]\tlr: 7.813e-05, eta: 0:00:26, time: 0.203, data_time: 0.087, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.5397, loss: 0.5397, grad_norm: 10.7646\n",
            "2021-04-16 20:50:41,691 - mmaction - INFO - Epoch [26][15/15]\tlr: 7.813e-05, eta: 0:00:24, time: 0.109, data_time: 0.037, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.4192, loss: 0.4192, grad_norm: 8.5510\n",
            "2021-04-16 20:50:45,719 - mmaction - INFO - Epoch [27][5/15]\tlr: 7.813e-05, eta: 0:00:22, time: 0.788, data_time: 0.650, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.5918, loss: 0.5918, grad_norm: 11.3910\n",
            "2021-04-16 20:50:46,901 - mmaction - INFO - Epoch [27][10/15]\tlr: 7.813e-05, eta: 0:00:20, time: 0.236, data_time: 0.106, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.4481, loss: 0.4481, grad_norm: 9.5173\n",
            "2021-04-16 20:50:47,645 - mmaction - INFO - Epoch [27][15/15]\tlr: 7.813e-05, eta: 0:00:18, time: 0.149, data_time: 0.062, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3865, loss: 0.3865, grad_norm: 8.2083\n",
            "2021-04-16 20:50:51,616 - mmaction - INFO - Epoch [28][5/15]\tlr: 7.813e-05, eta: 0:00:16, time: 0.776, data_time: 0.644, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5439, loss: 0.5439, grad_norm: 11.2009\n",
            "2021-04-16 20:50:52,637 - mmaction - INFO - Epoch [28][10/15]\tlr: 7.813e-05, eta: 0:00:14, time: 0.205, data_time: 0.071, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4845, loss: 0.4845, grad_norm: 9.9161\n",
            "2021-04-16 20:50:53,555 - mmaction - INFO - Epoch [28][15/15]\tlr: 7.813e-05, eta: 0:00:12, time: 0.184, data_time: 0.091, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3129, loss: 0.3129, grad_norm: 6.3263\n",
            "2021-04-16 20:50:57,980 - mmaction - INFO - Epoch [29][5/15]\tlr: 7.813e-05, eta: 0:00:10, time: 0.867, data_time: 0.744, memory: 2918, top1_acc: 1.0000, top5_acc: 1.0000, loss_cls: 0.3143, loss: 0.3143, grad_norm: 6.6434\n",
            "2021-04-16 20:50:58,932 - mmaction - INFO - Epoch [29][10/15]\tlr: 7.813e-05, eta: 0:00:08, time: 0.191, data_time: 0.082, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.4967, loss: 0.4967, grad_norm: 10.3034\n",
            "2021-04-16 20:50:59,623 - mmaction - INFO - Epoch [29][15/15]\tlr: 7.813e-05, eta: 0:00:06, time: 0.138, data_time: 0.052, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5301, loss: 0.5301, grad_norm: 10.5849\n",
            "2021-04-16 20:51:03,910 - mmaction - INFO - Epoch [30][5/15]\tlr: 7.813e-05, eta: 0:00:04, time: 0.840, data_time: 0.708, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.6780, loss: 0.6780, grad_norm: 13.5806\n",
            "2021-04-16 20:51:04,998 - mmaction - INFO - Epoch [30][10/15]\tlr: 7.813e-05, eta: 0:00:02, time: 0.218, data_time: 0.082, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6271, loss: 0.6271, grad_norm: 12.5527\n",
            "2021-04-16 20:51:05,644 - mmaction - INFO - Epoch [30][15/15]\tlr: 7.813e-05, eta: 0:00:00, time: 0.129, data_time: 0.057, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.5678, loss: 0.5678, grad_norm: 11.6980\n",
            "2021-04-16 20:51:05,728 - mmaction - INFO - Saving checkpoint at 30 epochs\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 5.5 task/s, elapsed: 2s, ETA:     0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 20:51:07,981 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
            "2021-04-16 20:51:07,983 - mmaction - INFO - \n",
            "top1_acc\t1.0000\n",
            "top5_acc\t1.0000\n",
            "2021-04-16 20:51:07,986 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
            "2021-04-16 20:51:07,989 - mmaction - INFO - \n",
            "mean_acc\t1.0000\n",
            "2021-04-16 20:51:07,990 - mmaction - INFO - Epoch(val) [30][15]\ttop1_acc: 1.0000, top5_acc: 1.0000, mean_class_accuracy: 1.0000\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryVoSfZVmogw"
      },
      "source": [
        "# Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVbmnPA5ATPe"
      },
      "source": [
        "from mmaction.apis import single_gpu_test\n",
        "from mmaction.datasets import build_dataloader\n",
        "from mmcv.parallel import MMDataParallel\n",
        "\n",
        "# Build a test dataloader\n",
        "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
        "data_loader = build_dataloader(\n",
        "        dataset,\n",
        "        videos_per_gpu=1,\n",
        "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
        "        dist=False,\n",
        "        shuffle=False)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ESE6OqDjbrMT",
        "outputId": "9fc83ad4-e9f3-4f60-d7a0-86629016c651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "md_model = MMDataParallel(model, device_ids=[0])\n",
        "\n",
        "outputs = single_gpu_test(md_model, data_loader)\n",
        "eval_config = cfg.evaluation\n",
        "eval_config.pop('interval',None)\n",
        "eval_res = dataset.evaluate(outputs, **eval_config)\n",
        "for name, val in eval_res.items():\n",
        "    print(f'{name}: {val:.04f}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 3.1 task/s, elapsed: 3s, ETA:     0s\n",
            "Evaluating top_k_accuracy ...\n",
            "\n",
            "top1_acc\t1.0000\n",
            "top5_acc\t1.0000\n",
            "\n",
            "Evaluating mean_class_accuracy ...\n",
            "\n",
            "mean_acc\t1.0000\n",
            "top1_acc: 1.0000\n",
            "top5_acc: 1.0000\n",
            "mean_class_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "k-l5XeyUbrMT",
        "outputId": "421b64a5-337d-46c8-b42a-80313c2a5a72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_loader"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f4ae7dcb610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Rw123XWibrMU"
      },
      "source": [
        "imgs =[]\n",
        "labels = []\n",
        "for d in data_loader:\n",
        "    imgs.append(d['imgs'].to(torch.device('cuda')))\n",
        "    labels.append(d['label'].to(torch.device('cuda')))\n",
        "labels = torch.stack(labels)\n",
        "# imgs = imgs.view(imgs.size(0),imgs.size(1),imgs.size(-2),imgs.size(-1),imgs.size(2))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dFDyEwPZbrMU",
        "outputId": "646ed0fe-a487-42b4-ab0b-e448b212d3f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mmaction2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FAFM1m9GbrMU",
        "outputId": "9a7c8e84-cbd4-4887-b845-f70eb27ca871",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "!rm -rf adversarial-robustness-toolbox\n",
        "!rm -rf adversarial_robustness_toolbox\n",
        "!git clone https://github.com/gabeorlanski/adversarial-robustness-toolbox.git\n",
        "\n",
        "%cd adversarial-robustness-toolbox/\n",
        "!git fetch\n",
        "!git checkout current_over_the_air\n",
        "%cd ..\n",
        "!mv adversarial-robustness-toolbox adversarial_robustness_toolbox "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'adversarial-robustness-toolbox'...\n",
            "remote: Enumerating objects: 54106, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 54106 (delta 13), reused 15 (delta 4), pack-reused 54074\u001b[K\n",
            "Receiving objects: 100% (54106/54106), 185.80 MiB | 24.98 MiB/s, done.\n",
            "Resolving deltas: 100% (42747/42747), done.\n",
            "/content/mmaction2/adversarial-robustness-toolbox\n",
            "Branch 'current_over_the_air' set up to track remote branch 'current_over_the_air' from 'origin'.\n",
            "Switched to a new branch 'current_over_the_air'\n",
            "/content/mmaction2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "56vNbfxUbrMU",
        "outputId": "bea76cda-9184-456e-fd84-c0c56b0e5abb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746,
          "referenced_widgets": [
            "e5abf1bbf3bd4dde9b78d8a43372ce88",
            "7df478822ddd45a29dbc71e9f39a1882",
            "2907d6b54b1e463b899a0aaaf67b4b5d",
            "6be46db68c84459f9e3b5165878c5f1c",
            "34461d3de2ad4019acd8776c96b73e33",
            "2ba89824e8654f32865028fbc049c443",
            "e72845e709f841ca90b71cf13eea30f8",
            "7f2d3bdc715a4a7a8e4700fca5d4d3d6"
          ]
        }
      },
      "source": [
        "from scipy.special import expit\n",
        "from adversarial_robustness_toolbox.over_the_air import paper_equations\n",
        "from importlib import reload\n",
        "from tqdm.notebook import tqdm\n",
        "torch.manual_seed(2020)\n",
        "reload(paper_equations)\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "delta = nn.parameter.Parameter(torch.zeros(imgs[0].shape[1],3,1,1).normal_(mean=0.,std=.2).to(torch.device('cuda')),requires_grad=True)\n",
        "optimizer = torch.optim.AdamW([delta],lr=1.)\n",
        "schedueler = torch.optim.lr_scheduler.StepLR(optimizer, 10)\n",
        "for i in tqdm(range(200)):\n",
        "    optimizer.zero_grad()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for vid in imgs:\n",
        "            preds.append(expit(model(vid+delta,return_loss=False)))\n",
        "    preds = torch.tensor(preds).to(torch.device('cuda')).squeeze(1)\n",
        "    loss = paper_equations.objectiveFunc(\n",
        "        preds,\n",
        "        labels.squeeze(1),\n",
        "        delta,\n",
        "        .6,\n",
        "        1,\n",
        "        1,\n",
        "        .25\n",
        "    )\n",
        "    if (i+1) % 5 == 0:\n",
        "        tqdm.write(f\"Epoch {i+1:>4}: Loss {loss:.7f}\")\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    schedueler.step()\n",
        "    "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5abf1bbf3bd4dde9b78d8a43372ce88",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch    5: Loss 2.8424351\n",
            "Epoch   10: Loss 1.6641532\n",
            "Epoch   15: Loss 0.8904557\n",
            "Epoch   20: Loss 0.5817024\n",
            "Epoch   25: Loss 0.5749580\n",
            "Epoch   30: Loss 0.5745787\n",
            "Epoch   35: Loss 0.5741915\n",
            "Epoch   40: Loss 0.5738820\n",
            "Epoch   45: Loss 0.5737765\n",
            "Epoch   50: Loss 0.5737303\n",
            "Epoch   55: Loss 0.5737163\n",
            "Epoch   60: Loss 0.5737108\n",
            "Epoch   65: Loss 0.5737092\n",
            "Epoch   70: Loss 0.5737086\n",
            "Epoch   75: Loss 0.5737084\n",
            "Epoch   80: Loss 0.5737084\n",
            "Epoch   85: Loss 0.5737084\n",
            "Epoch   90: Loss 0.5737083\n",
            "Epoch   95: Loss 0.5737084\n",
            "Epoch  100: Loss 0.5737084\n",
            "Epoch  105: Loss 0.5737084\n",
            "Epoch  110: Loss 0.5737084\n",
            "Epoch  115: Loss 0.5737084\n",
            "Epoch  120: Loss 0.5737084\n",
            "Epoch  125: Loss 0.5737084\n",
            "Epoch  130: Loss 0.5737084\n",
            "Epoch  135: Loss 0.5737084\n",
            "Epoch  140: Loss 0.5737084\n",
            "Epoch  145: Loss 0.5737084\n",
            "Epoch  150: Loss 0.5737084\n",
            "Epoch  155: Loss 0.5737084\n",
            "Epoch  160: Loss 0.5737084\n",
            "Epoch  165: Loss 0.5737084\n",
            "Epoch  170: Loss 0.5737084\n",
            "Epoch  175: Loss 0.5737084\n",
            "Epoch  180: Loss 0.5737084\n",
            "Epoch  185: Loss 0.5737084\n",
            "Epoch  190: Loss 0.5737084\n",
            "Epoch  195: Loss 0.5737084\n",
            "Epoch  200: Loss 0.5737084\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vbyYr2CCbrMV",
        "outputId": "24a105f7-9f64-40fd-e65f-9fa507210819",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "preds = []\n",
        "with torch.no_grad():\n",
        "    for vid in imgs:\n",
        "        preds.append(np.argmax(expit(model(vid+delta,return_loss=False)),axis=1))\n",
        "print(f\"Original:\")\n",
        "eval_config = cfg.evaluation\n",
        "eval_config.pop('interval',None)\n",
        "eval_res = dataset.evaluate(outputs, **eval_config)\n",
        "for name, val in eval_res.items():\n",
        "    print(f'{name}: {val:.04f}')\n",
        "print(f\"\\n\\n\\nAttack:\")\n",
        "eval_res = dataset.evaluate(preds, **eval_config)\n",
        "for name, val in eval_res.items():\n",
        "    print(f'{name}: {val:.04f}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:\n",
            "\n",
            "Evaluating top_k_accuracy ...\n",
            "\n",
            "top1_acc\t1.0000\n",
            "top5_acc\t1.0000\n",
            "\n",
            "Evaluating mean_class_accuracy ...\n",
            "\n",
            "mean_acc\t1.0000\n",
            "top1_acc: 1.0000\n",
            "top5_acc: 1.0000\n",
            "mean_class_accuracy: 1.0000\n",
            "\n",
            "\n",
            "\n",
            "Attack:\n",
            "\n",
            "Evaluating top_k_accuracy ...\n",
            "\n",
            "top1_acc\t0.5000\n",
            "top5_acc\t0.5000\n",
            "\n",
            "Evaluating mean_class_accuracy ...\n",
            "\n",
            "mean_acc\t0.5000\n",
            "top1_acc: 0.5000\n",
            "top5_acc: 0.5000\n",
            "mean_class_accuracy: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bxl8RwFXbrMV",
        "outputId": "b5ae7474-836a-4646-b50a-b8c02558cd90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7349, device='cuda:0', grad_fn=<NormBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "HHRbdB5DbrMV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyY3hCMwyTct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b40b91-e325-41b8-d4e2-8b5874b2bbba"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 3.1 task/s, elapsed: 3s, ETA:     0s\n",
            "Evaluating top_k_accuracy ...\n",
            "\n",
            "top1_acc\t1.0000\n",
            "top5_acc\t1.0000\n",
            "\n",
            "Evaluating mean_class_accuracy ...\n",
            "\n",
            "mean_acc\t1.0000\n",
            "top1_acc: 1.0000\n",
            "top5_acc: 1.0000\n",
            "mean_class_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeoDjGRxCFdj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VR9EUPXYXNs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}